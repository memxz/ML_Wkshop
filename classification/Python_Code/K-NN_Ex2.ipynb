{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with large data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the Iris data sets from sklearn as our example\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris # see what the dataset is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe with the data\n",
    "# first four columns are the features, the last column is the target that we want to predict\n",
    "df = pd.DataFrame(iris.data, columns = ['sepal length (cm)',\n",
    "  'sepal width (cm)',\n",
    "  'petal length (cm)',\n",
    "  'petal width (cm)'])\n",
    "df['class'] = iris.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names) # these are the class names corresponding to their numeric label [0, 1, 2 ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the sepal dimesnions as the features\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we let k = 5 first, which means choosing 5 nearest neighbors.\n",
    "knn = KNeighborsClassifier(n_neighbors = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:2], df['class'], random_state = 42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred) # our prediction\n",
    "print(y_test) # actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should test how accurate our model is \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closer to 1 accuracy score means better prediction. Our model has an accuracy score of 0.815 approximately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore more about model\n",
    "\n",
    "We can try use different k values for our model.\n",
    "Check its accuracy with these k values.<br>\n",
    "\n",
    "We will try k = 1 to k =20, as smaller k means noises have large influence and larger k means comuptation becomes expensive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_array = np.arange(1, 21, 2)\n",
    "\n",
    "k_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change k value to 1 - 20, and check the accuracy score\n",
    "# Then we can choose the optimized k value\n",
    "\n",
    "for k in k_array:\n",
    "    knn_ex = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn_ex.fit(X_train, y_train)\n",
    "    ac = accuracy_score(y_test, knn_ex.predict(X_test))\n",
    "    print(k)\n",
    "    print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn_1.fit(X_train, y_train)\n",
    "y_pred1 = knn_1.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model using different numbers of trees varys. Choosing a optimized value for our model is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with Confusion Matrix\n",
    "We can use Confusion Matrix to see how the prediction goes.\n",
    "The matrix has the format:\n",
    "\n",
    "|+                  |actual classA | actual classB| |\n",
    "|-------------------|--------------|--------|-----|\n",
    "|predicted classA   |              |        |     |\n",
    "|predicted classB   |              |        |     |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Confusion Matrix shows that we have 15 predicted class 0 are correct.\n",
    "7 predicted class 1 are correct; 4 predicted class 1 which are actually class 2.\n",
    "9 predicted class 2 are correct; 3 predicted class 2 which are actually class 1 .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix when k = 1\n",
    "confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F1 score can be interpreted as a weighted average of the precision and recall, \n",
    "# where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred1, average = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Our accuracy score got from finding the suitable k is between 0.7 to 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
