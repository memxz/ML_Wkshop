{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cf9b32-4d67-4008-b968-1b4c5398b304",
   "metadata": {},
   "source": [
    "<h1>Baseline Model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54f89818-da32-415e-a549-6861fa719eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f74839-9b40-4f0b-b795-b29887a09826",
   "metadata": {},
   "source": [
    "<h3>Prepare Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4c0711e-7112-45a9-8295-19c5a8eebf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImagePaths(dir):\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    for folder in os.listdir(dir):\n",
    "        folder_path = os.path.join(dir,folder)\n",
    "        for image in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path,image)\n",
    "            if image[0] == '.':\n",
    "                continue\n",
    "            if 'train' in folder_path:\n",
    "                train_paths.append(image_path)\n",
    "            else:\n",
    "                test_paths.append(image_path)\n",
    "    return train_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f70c7edb-7d87-4caa-b11e-7a50c68362ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToArray(image_path):\n",
    "    image = io.imread(image_path) # convert to np array\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53df9a72-369d-45f6-ba1b-bf284196fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resize(image):\n",
    "    image = Image.fromarray(image, 'RGB') # convert np array to PIL img and turns it from rgba to rgb\n",
    "    image = image.resize((224,224)) # resie PIL img\n",
    "    return np.array(image) # convert image back to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9f1a17f-c558-4800-8b70-83d51d26a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(image): # Normalize images\n",
    "    image = image/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86adf124-aa91-43ad-93df-830c8cddf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetX(train_paths,test_paths):\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    for path in train_paths:\n",
    "        image = ToArray(path)\n",
    "        image = Resize(image)\n",
    "        image = Normalize(image)\n",
    "        train_images.append(image)\n",
    "    for path in test_paths:\n",
    "        image = ToArray(path)\n",
    "        image = Resize(image)\n",
    "        image = Normalize(image)\n",
    "        test_images.append(image)\n",
    "    return np.array(train_images), np.array(test_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c498a43e-993c-4ddc-a771-972d89536cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetY(image_paths):\n",
    "    countApple = len([path_text for path_text in image_paths if 'apple' in path_text.lower()]) # count number of apple images\n",
    "    countBanana = len([path_text for path_text in image_paths if 'banana' in path_text.lower()]) # count number of banana images\n",
    "    countMixed = len([path_text for path_text in image_paths if 'mixed' in path_text.lower()]) # count number of mixed images\n",
    "    countOrange = len([path_text for path_text in image_paths if 'orange' in path_text.lower()]) # count number of orange images\n",
    "    y = np.concatenate((['apple']*countApple,['banana']*countBanana,['mixed']*countMixed,['orange']*countOrange)) # combine list of items and convert to 1Darray\n",
    "    y = y.reshape(-1,1) # reshape from 1D array to 2D array because ohe only takes in 2D array\n",
    "    ohe = OneHotEncoder()\n",
    "    return ohe.fit_transform(y).toarray() # returns the fitted ohe and values to be used as Y_train or Y_test (labels for comparing predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ea68f64-3ae3-4008-9dfe-cceb3f6f7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetXYSets(train_paths, test_paths):\n",
    "    X_train, X_test = GetX(train_paths, test_paths)\n",
    "    Y_train = GetY(train_paths)\n",
    "    Y_test = GetY(test_paths)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c002163-bc89-4934-8866-12cd76b8b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowSecret():\n",
    "     img = io.imshow(r'Data\\Private\\secretpictures.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802507ac-7280-4f29-944e-32448ef40650",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc7921a-7ece-42a1-ad7e-563a6c067937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths = GetImagePaths(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "823424b8-17c4-4939-a495-bfef9bafe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = GetXYSets(train_paths,test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbda706-2614-423f-bd54-f5acfbeeb278",
   "metadata": {},
   "source": [
    "<h3>Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06279ea-46a3-48a3-9648-a0fc1b717ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Sequential([\n",
    "    Conv2D(32,(3,3), activation = 'relu', input_shape=(224,224,3)),\n",
    "    Conv2D(32,(3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2),(2,2)),\n",
    "    \n",
    "    Conv2D(32,(3,3), activation='relu'),\n",
    "    Conv2D(32,(3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2),(2,2)),\n",
    "    \n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ce212c3-cac8-4e01-8552-40c7d8487c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4f255ac-0954-4a86-83ad-3ea6049c3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06720b86-e385-4631-ae9e-767ad2fa11f3",
   "metadata": {},
   "source": [
    "<h3>Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7ee962c-1d9c-4880-8b05-9e3e726f0674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 3s 171ms/step - loss: 1.3842 - accuracy: 0.3000 - val_loss: 1.3652 - val_accuracy: 0.3000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.3542 - accuracy: 0.3458 - val_loss: 1.3199 - val_accuracy: 0.3000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.3169 - accuracy: 0.3167 - val_loss: 1.2906 - val_accuracy: 0.3000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.2901 - accuracy: 0.3417 - val_loss: 1.2810 - val_accuracy: 0.3167\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.2705 - accuracy: 0.4333 - val_loss: 1.2257 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.2107 - accuracy: 0.5167 - val_loss: 1.1675 - val_accuracy: 0.5333\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.0867 - accuracy: 0.6458 - val_loss: 1.0659 - val_accuracy: 0.7000\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.9834 - accuracy: 0.6667 - val_loss: 1.0827 - val_accuracy: 0.7333\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.9305 - accuracy: 0.6708 - val_loss: 1.0471 - val_accuracy: 0.6167\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.8697 - accuracy: 0.6708 - val_loss: 1.0799 - val_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.8317 - accuracy: 0.6667 - val_loss: 1.0610 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.8007 - accuracy: 0.7083 - val_loss: 0.9546 - val_accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7378 - accuracy: 0.7917 - val_loss: 0.8598 - val_accuracy: 0.8167\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.6877 - accuracy: 0.7750 - val_loss: 0.8492 - val_accuracy: 0.7833\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.6450 - accuracy: 0.7708 - val_loss: 0.7693 - val_accuracy: 0.8167\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.5747 - accuracy: 0.8125 - val_loss: 0.7418 - val_accuracy: 0.8167\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.5829 - accuracy: 0.7958 - val_loss: 0.6872 - val_accuracy: 0.8167\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5057 - accuracy: 0.8417 - val_loss: 0.6549 - val_accuracy: 0.8333\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.4782 - accuracy: 0.8417 - val_loss: 0.6585 - val_accuracy: 0.8167\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.4744 - accuracy: 0.8542 - val_loss: 0.5841 - val_accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.4814 - accuracy: 0.8292 - val_loss: 0.5932 - val_accuracy: 0.8167\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.4938 - accuracy: 0.8583 - val_loss: 0.5639 - val_accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.4061 - accuracy: 0.8708 - val_loss: 0.5830 - val_accuracy: 0.8167\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3546 - accuracy: 0.8833 - val_loss: 0.5435 - val_accuracy: 0.8167\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3351 - accuracy: 0.9125 - val_loss: 0.5058 - val_accuracy: 0.8167\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3137 - accuracy: 0.9125 - val_loss: 0.4937 - val_accuracy: 0.8167\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3032 - accuracy: 0.9000 - val_loss: 0.5328 - val_accuracy: 0.8500\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3484 - accuracy: 0.9083 - val_loss: 0.5443 - val_accuracy: 0.8167\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2864 - accuracy: 0.9208 - val_loss: 0.4700 - val_accuracy: 0.8167\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2680 - accuracy: 0.9167 - val_loss: 0.5279 - val_accuracy: 0.8000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2763 - accuracy: 0.9125 - val_loss: 0.4733 - val_accuracy: 0.8167\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2643 - accuracy: 0.9250 - val_loss: 0.4705 - val_accuracy: 0.8500\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2525 - accuracy: 0.9333 - val_loss: 0.4413 - val_accuracy: 0.8333\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2726 - accuracy: 0.9125 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2821 - accuracy: 0.9042 - val_loss: 0.5038 - val_accuracy: 0.8167\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2862 - accuracy: 0.8917 - val_loss: 0.5300 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2686 - accuracy: 0.9083 - val_loss: 0.5236 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2459 - accuracy: 0.9042 - val_loss: 0.4640 - val_accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.2359 - accuracy: 0.9417 - val_loss: 0.5811 - val_accuracy: 0.8667\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2292 - accuracy: 0.9083 - val_loss: 0.4714 - val_accuracy: 0.8500\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2816 - accuracy: 0.9083 - val_loss: 0.4242 - val_accuracy: 0.8500\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2255 - accuracy: 0.9250 - val_loss: 0.5963 - val_accuracy: 0.8500\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2276 - accuracy: 0.9167 - val_loss: 0.4434 - val_accuracy: 0.8333\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1861 - accuracy: 0.9250 - val_loss: 0.4520 - val_accuracy: 0.8667\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1760 - accuracy: 0.9375 - val_loss: 0.5006 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1789 - accuracy: 0.9375 - val_loss: 0.4655 - val_accuracy: 0.8500\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.4683 - val_accuracy: 0.8833\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2054 - accuracy: 0.9333 - val_loss: 0.4198 - val_accuracy: 0.8500\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2481 - accuracy: 0.9000 - val_loss: 0.5558 - val_accuracy: 0.8167\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3082 - accuracy: 0.9083 - val_loss: 0.7600 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "callback = baseline.fit(X_train,Y_train,epochs=50,validation_data=(X_test,Y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e867ed-d1ab-47c8-b9f2-a44b5d5a7495",
   "metadata": {},
   "source": [
    "<h3>Save Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ced40b7b-a59c-4832-9a35-6e0704cef370",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.save(\"baseline.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f753f27c-846e-4c42-967e-a72567040576",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Records.pkl', 'wb') as file_pi: # saving training data\n",
    "    pickle.dump(callback.history, file_pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
